#
# Author : Alwyn Mathew
#
# Monodepth in pytorch(https://github.com/alwynmathew/monodepth-pytorch)
# Bilinear sampler in pytorch(https://github.com/alwynmathew/bilinear-sampler-pytorch)
#

from __future__ import absolute_import, division, print_function
import torch
from torch.nn.functional import pad
import matplotlib.pyplot as plt
from sintel_io import disparity_read
import numpy as np

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")


def apply_disparity(input_images, x_offset, wrap_mode='border', tensor_type = 'torch.cuda.FloatTensor'):
    num_batch, num_channels, height, width = input_images.size()

    # Handle both texture border types
    edge_size = 0
    if wrap_mode == 'border':
        edge_size = 1
        # Pad last and second-to-last dimensions by 1 from both sides
        input_images = pad(input_images, (1, 1, 1, 1))
    elif wrap_mode == 'edge':
        edge_size = 0
    else:
        return None

    # Put channels to slowest dimension and flatten batch with respect to others
    input_images = input_images.permute(1, 0, 2, 3).contiguous()
    im_flat = input_images.view(num_channels, -1)

    # Create meshgrid for pixel indicies (PyTorch doesn't have dedicated
    # meshgrid function)
    x = torch.linspace(0, width - 1, width).repeat(height, 1).type(tensor_type).to(device)
    y = torch.linspace(0, height - 1, height).repeat(width, 1).transpose(0, 1).type(tensor_type).to(device)
    # Take padding into account
    x = x + edge_size
    y = y + edge_size
    # Flatten and repeat for each image in the batch
    x = x.view(-1).repeat(1, num_batch)
    y = y.view(-1).repeat(1, num_batch)

    # Now we want to sample pixels with indicies shifted by disparity in X direction
    # For that we convert disparity from % to pixels and add to X indicies
    # x = x + x_offset.contiguous().view(-1) * width
    x = x + x_offset.contiguous().view(-1)
    # Make sure we don't go outside of image
    x = torch.clamp(x, 0.0, width - 1 + 2 * edge_size)
    # Round disparity to sample from integer-valued pixel grid
    y0 = torch.floor(y)
    # In X direction round both down and up to apply linear interpolation
    # between them later
    x0 = torch.floor(x)
    x1 = x0 + 1
    # After rounding up we might go outside the image boundaries again
    x1 = x1.clamp(max=(width - 1 + 2 * edge_size))

    # Calculate indices to draw from flattened version of image batch
    dim2 = (width + 2 * edge_size)
    dim1 = (width + 2 * edge_size) * (height + 2 * edge_size)
    # Set offsets for each image in the batch
    base = dim1 * torch.arange(num_batch).type(tensor_type).to(device)
    base = base.view(-1, 1).repeat(1, height * width).view(-1)
    # One pixel shift in Y  direction equals dim2 shift in flattened array
    base_y0 = base + y0 * dim2
    # Add two versions of shifts in X direction separately
    idx_l = base_y0 + x0
    idx_r = base_y0 + x1

    # Sample pixels from images
    pix_l = im_flat.gather(1, idx_l.repeat(num_channels, 1).long())
    pix_r = im_flat.gather(1, idx_r.repeat(num_channels, 1).long())

    # Apply linear interpolation to account for fractional offsets
    weight_l = x1 - x
    weight_r = x - x0
    output = weight_l * pix_l + weight_r * pix_r

    # Reshape back into image batch and permute back to (N,C,H,W) shape
    output = output.view(num_channels, num_batch, height, width).permute(1,0,2,3)

    return output


def geneate_right(left_img, disp):
    right_img = torch.zeros_like(left_img)
    for i in range(right_img.shape[1]):
        for j in range(right_img.shape[2]):
            if i == 188 and j == 460:
                print ("AAA")

            disp_x = torch.clamp(torch.floor(disp[i,j]).long(),0,1e9)
            right_img[:,i,j-disp_x] = left_img[:,i, j]

    return right_img




def example():
    dis = disparity_read('/media/yotamg/bd0eccc9-4cd5-414c-b764-c5a7890f9785/Yotam/Sintel/disparities/alley_1/frame_0001.png')
    left_image = plt.imread('/media/yotamg/bd0eccc9-4cd5-414c-b764-c5a7890f9785/Yotam/Sintel/clean_left/alley_1/frame_0001.png')
    right_img = plt.imread('/media/yotamg/bd0eccc9-4cd5-414c-b764-c5a7890f9785/Yotam/Sintel/clean_right/alley_1/frame_0001.png')
    ax1 = plt.subplot(221)
    plt.imshow(left_image)
    plt.subplot(222, sharex=ax1, sharey=ax1)
    plt.imshow(right_img)
    plt.subplot(223, sharex=ax1, sharey=ax1)
    plt.imshow(dis)
    left_image = torch.Tensor(np.transpose(left_image, (2,0,1)))
    left_image = torch.unsqueeze(left_image,0).to(device)
    dis = torch.Tensor(dis).to(device)
    # b = geneate_right(left_image,dis)
    b = apply_disparity(left_image, dis)
    plt.subplot(224, sharex=ax1, sharey=ax1)
    plt.imshow(b[0].permute(1,2,0))
    plt.show()
    print ("Done")

if __name__ == '__main__':
    example()